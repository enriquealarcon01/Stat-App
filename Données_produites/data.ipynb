{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Récupération et formatage des données**\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction<a class=\"anchor\" id=\"partie1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook contient les codes nécessaires à la récupération et au formatage des données. Les données ont été récupéré sur le site de [l'OCDE](https://data-explorer.oecd.org/) et sur celui [d'Eurostat](https://ec.europa.eu/eurostat/fr/data/database). \n",
    "\n",
    "Nous récupérons les données en csv et les transformons en un unique csv contenant pour chacun des pays les valeurs trimestrielles (de Q1 en 1995 à Q3 de 2024 <span style=\"color:red ; font-size:20px;\"> faire attention les working hours ne vont qu'au Q3 de 2024 </span>) de PIB, d'heure de travail, des taux d'intérêts à court et long terme et de l'indice à la consommation des prix. Pour l'instant il nous manque aussi les anticipations des taux et les rendements des marchés financiers. Le csv final de ce notebook servira de base de données par la suite. \n",
    "\n",
    "Les pays retenus sont ceux pour lesquels on a réussi à collecter toutes les données relatives aux variables d'intérêt: Autriche (Austria) Belgique (Belgium) Bulgarie (Bulgaria) Tchéquie (Czechia) Danemark (Denmark) Estonie (Estonia) Finlande (Finland) France (France) Allemagne (Germany) Grèce (Greece) Hongrie (Hungary) Islande (Iceland) Irlande (Ireland) Italie (Italy) Lettonie (Latvia) Lituanie (Lithuania) Luxembourg (Luxembourg) Pays-Bas (Netherlands) Norvège (Norway) Pologne (Poland) Portugal (Portugal) Roumanie (Romania) Slovaquie (Slovakia) Slovénie (Slovenia) Espagne (Spain) Suède (Sweden) Suisse (Switzerland) Royaume-Uni (United Kingdom).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sommaire\n",
    "\n",
    "* [Introduction](#partie1)\n",
    "* [Récupération des données](#partie2)\n",
    "    * [Données de PIB](#partie21)\n",
    "    * [Données d'heures de travail](#partie22)\n",
    "    * [Données des taux d'intérêts](#partie23)\n",
    "    * [Données d'indice à la consommation des prix](#partie24)\n",
    "    * [Données de croissance potentielle](#partie25)\n",
    "* [Création de la base de données](#partie3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Récupération des données <a class=\"anchor\" id=\"partie2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous créons la liste qui contient les pays cités précédemment, à noter que la Slovaquie apparaît sous le nom Slovakia pour Eurostat et Slovak Republic pour l'OCDE, elle est donc sous deux noms dans notre liste de pays à sélectionner. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste comportant les pays choisis\n",
    "countries_selected=[\n",
    "    \"Austria\", \"Belgium\", \"Bulgaria\", \"Czechia\", \"Czech Republic\", \"Denmark\", \"Estonia\", \n",
    "    \"Finland\", \"France\", \"Germany\", \"Greece\", \"Hungary\", \"Iceland\", \n",
    "    \"Ireland\", \"Italy\", \"Latvia\", \"Lithuania\", \"Luxembourg\", \"Netherlands\", \n",
    "    \"Norway\", \"Poland\", \"Portugal\", \"Romania\", \"Slovakia\", \"Slovak Republic\",\n",
    "    \"Slovenia\", \"Spain\", \"Sweden\", \"Switzerland\", \"United Kingdom\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données de PIB <a class=\"anchor\" id=\"partie21\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous extrayons les données relatives au PIB depuis Eurostat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Données_extraites/GDP_trimestriel_eurostat.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Chargement des données \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df_GDP = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDonnées_extraites/GDP_trimestriel_eurostat.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Sélection des colonnes nécessaires avec les pays sélectionnés\u001b[39;00m\n\u001b[32m      5\u001b[39m df_GDP_selected = df_GDP[df_GDP[\u001b[33m'\u001b[39m\u001b[33mgeo\u001b[39m\u001b[33m'\u001b[39m].isin(countries_selected)][[\u001b[33m'\u001b[39m\u001b[33mgeo\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mTIME_PERIOD\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mOBS_VALUE\u001b[39m\u001b[33m'\u001b[39m]]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/pandas/io/common.py:882\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    883\u001b[39m     handles.append(handle)\n\u001b[32m    885\u001b[39m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'Données_extraites/GDP_trimestriel_eurostat.csv'"
     ]
    }
   ],
   "source": [
    "# Chargement des données \n",
    "df_GDP = pd.read_csv(\"Données_extraites/GDP_trimestriel_eurostat.csv\", encoding='utf-8')\n",
    "Stat-App/Données_extraites/GDP_trimestriel_eurostat.csv\n",
    "# Sélection des colonnes nécessaires avec les pays sélectionnés\n",
    "df_GDP_selected = df_GDP[df_GDP['geo'].isin(countries_selected)][['geo', 'TIME_PERIOD', 'OBS_VALUE']]\n",
    "\n",
    "# Modification du format pour avoir les périodes en index et les noms des pays en nom de colonnes\n",
    "df_GDP = df_GDP_selected.pivot_table(index='TIME_PERIOD', columns='geo', values='OBS_VALUE')\n",
    "\n",
    "# Transformation des colonnes en PIB_Nom_du_pays\n",
    "df_GDP.columns = [f'PIB_{col}' for col in df_GDP.columns]\n",
    "df_GDP.columns = [col.replace(\" \", \"_\") for col in df_GDP.columns]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données de d'heure de travail <a class=\"anchor\" id=\"partie22\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous extrayons les données relatives aux heures de travail depuis Eurostat. Nous avons trois base de données pour les heures de travail. Une base annuelle de 1995 à 1997, et deux bases trimestrielles allant du Q1 de 1998 au Q4 de 2007 et du Q1 de 2008 au Q3 de 2024.\n",
    "\n",
    "Nous voulons traiter les données dans l'ordre chronologique. Nous devons donc pour la première période récupérer les données annuelles et les transformer en trimestrielles, nous choisissons d'interpoler les données manquantes de manière linéaire en donnant la valeur annuelle au Q1. Pour cela nous avons besoin de traiter les données de 1998 à 2007 avant afin de pouvoir faire l'interpolation entre le Q1 de 1997 et celui de 1998.\n",
    "\n",
    "Nous récupérons donc d'abord toutes les données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données de 1995 à 1997 \n",
    "df_working_hours_95_97 = pd.read_csv(\"Données_extraites/Working_hours_eurostat_1995-1997.csv\", encoding='utf-8')\n",
    "\n",
    "# Sélection des colonnes nécessaires avec les pays sélectionnés\n",
    "df_working_hours_95_97_selected = df_working_hours_95_97[df_working_hours_95_97['geo'].isin(countries_selected)][['geo', 'TIME_PERIOD', 'OBS_VALUE']]\n",
    "\n",
    "# Modification du format pour avoir les périodes en index et les noms des pays en nom de colonnes\n",
    "df_working_hours_95_97_pivot = df_working_hours_95_97_selected.pivot_table(index='TIME_PERIOD', columns='geo', values='OBS_VALUE')\n",
    "\n",
    "# Transformation des colonnes en WH_Nom_du_pays\n",
    "df_working_hours_95_97_pivot.columns = [f'WH_{col}' for col in df_working_hours_95_97_pivot.columns]\n",
    "df_working_hours_95_97_pivot.columns = [col.replace(\" \", \"_\") for col in df_working_hours_95_97_pivot.columns]\n",
    "\n",
    "# Même processus pour celles de 1998 à 2007 et celles de 2008 à 2024\n",
    "df_working_hours_98_07 = pd.read_csv(\"Données_extraites/Working_hours_eurostat_1998-2007.csv\", encoding='utf-8')\n",
    "df_working_hours_98_07_selected = df_working_hours_98_07[df_working_hours_98_07['geo'].isin(countries_selected)][['geo', 'TIME_PERIOD', 'OBS_VALUE']]\n",
    "df_working_hours_98_07_pivot = df_working_hours_98_07_selected.pivot_table(index='TIME_PERIOD', columns='geo', values='OBS_VALUE')\n",
    "df_working_hours_98_07_pivot.columns = [f'WH_{col}' for col in df_working_hours_98_07_pivot.columns]\n",
    "df_working_hours_98_07_pivot.columns = [col.replace(\" \", \"_\") for col in df_working_hours_98_07_pivot.columns]\n",
    "\n",
    "df_working_hours_08_24 = pd.read_csv(\"Données_extraites/Working_hours_eurostat_2008-2024.csv\", encoding='utf-8')\n",
    "df_working_hours_08_24_selected = df_working_hours_08_24[df_working_hours_08_24['geo'].isin(countries_selected)][['geo', 'TIME_PERIOD', 'OBS_VALUE']]\n",
    "df_working_hours_08_24_pivot = df_working_hours_08_24_selected.pivot_table(index='TIME_PERIOD', columns='geo', values='OBS_VALUE')\n",
    "df_working_hours_08_24_pivot.columns = [f'WH_{col}' for col in df_working_hours_08_24_pivot.columns]\n",
    "df_working_hours_08_24_pivot.columns = [col.replace(\" \", \"_\") for col in df_working_hours_08_24_pivot.columns]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et maintenant nous configurons l'interpolation. Pour clarifier le point précédent, l'interpolation est linéaire, donc va tracer une droite entre deux périodes avec une valeur présente et inférer une valeur aux périodes pour laquelle la valeur est manquante et qui se trouvent entre nos deux périodes. Comme nous faisons le choix de donner la valeur annuelle au Q1 il faut ajouter une valeur de 1998 pour pouvoir inférer les valeurs du Q2, Q3 et Q4 de 1997, ce que nous faisons donc en ajoutant le Q1 de 1998 à notre table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération du Q1 de 1998 et suppresion de la table pour éviter les doublons lors de la concaténation\n",
    "Q1_1998 =  df_working_hours_98_07_pivot.loc[['1998-Q1']]\n",
    "df_working_hours_98_07_pivot = df_working_hours_98_07_pivot.drop(index='1998-Q1', errors='ignore')\n",
    "\n",
    "# Ajout des trimestres vierges aux données de 1995 à 1998 pour ensuite les compléter par interpolation\n",
    "new_index = []\n",
    "values = []\n",
    "for year in df_working_hours_95_97_pivot.index:\n",
    "    # Ajout du Q1 pour chaque année (avec la valeur annuelle)\n",
    "    new_index.append(f\"{year}-Q1\")\n",
    "    values.append(df_working_hours_95_97_pivot.loc[year].values)\n",
    "    \n",
    "    # Ajouts des Q2, Q3 et Q4 (lignes vides pour l'instant)\n",
    "    for quarter in ['Q2', 'Q3', 'Q4']:\n",
    "        new_index.append(f\"{year}-{quarter}\")\n",
    "        values.append([None] * len(df_working_hours_95_97_pivot.columns))\n",
    "\n",
    "# Création du dataframe avec les lignes vides\n",
    "df_working_hours_95_97_pivot = pd.DataFrame(values, index=new_index, columns=df_working_hours_95_97_pivot.columns)\n",
    "df_working_hours_95_97_pivot.index.name = 'TIME_PERIOD'\n",
    "\n",
    "df_working_hours_95_97_pivot = pd.concat([df_working_hours_95_97_pivot, Q1_1998])\n",
    "\n",
    "# Interpolation\n",
    "df_working_hours_95_97_pivot = df_working_hours_95_97_pivot.interpolate(method='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant nous procédons à la concaténation des données pour avoir un unique dataframe contenant les heures de travail trimestrielles de 1995 à 2024. Seulement nous devons supprimer les index de 2008 dans le dataframe de 1998 à 2007 car sinon ils seraient en double lors de la concaténation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppresion des index\n",
    "df_working_hours_98_07_pivot = df_working_hours_98_07_pivot.drop(index = ['2008-Q1','2008-Q2', '2008-Q3','2008-Q4'] , errors='ignore')\n",
    "\n",
    "# Concaténation\n",
    "df_working_hours = pd.concat(\n",
    "    [df_working_hours_95_97_pivot, df_working_hours_98_07_pivot, df_working_hours_08_24_pivot], \n",
    "    axis=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données des taux d'intérêts <a class=\"anchor\" id=\"partie23\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour les taux d'intérêts nous récupérons des taux de long-terme, à savoir des obligations d'Etat à 10 ans, et des taux de court-terme. Les taux à court terme sont généralement soit le taux interbancaire à trois mois lié aux prêts accordés et acceptés par les banques pour tout excès ou manque de liquidité sur plusieurs mois, soit le taux associé aux bons du Trésor, aux certificats de dépôt ou à des instruments comparables, chacun d'une durée de trois mois. Pour les pays de la zone euro, le « European Interbank Offered Rate » à trois mois est utilisé à partir de la date à laquelle le pays a rejoint l'euro.  \n",
    "\n",
    "Nous commençons par récupérer les taux de long-terme puis ceux de court-terme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données\n",
    "df_LT_IR = pd.read_csv('Données_extraites/Long_term_IR_OCDE.csv', encoding='utf-8')\n",
    "\n",
    "# Sélection des colonnes nécessaires avec les pays sélectionnés\n",
    "df_LT_IR_selected = df_LT_IR[df_LT_IR['Reference area'].isin(countries_selected)][['Reference area', 'TIME_PERIOD', 'OBS_VALUE']]\n",
    "\n",
    "# Modification du format pour avoir les périodes en index et les noms des pays en nom de colonnes\n",
    "df_LT_IR = df_LT_IR_selected.pivot_table(index='TIME_PERIOD', columns='Reference area', values='OBS_VALUE')\n",
    "\n",
    "# Modification des colonnes pour inclure le préfixe LT_IR_ (=Long Term Interest Rate)\n",
    "df_LT_IR.columns = [f'LT_IR_{col}' for col in df_LT_IR.columns]\n",
    "df_LT_IR.columns = [col.replace(\" \", \"_\") for col in df_LT_IR.columns]\n",
    "df_LT_IR = df_LT_IR.rename(columns={'LT_IR_Slovak_Republic': 'LT_IR_Slovakia'})\n",
    "\n",
    "# Même processus pour les taux de long-terme\n",
    "df_ST_IR=pd.read_csv('Données_extraites/Short_term_IR_OCDE.csv', encoding='utf-8')\n",
    "df_ST_IR_selected = df_ST_IR[df_ST_IR['Reference area'].isin(countries_selected)][['Reference area', 'TIME_PERIOD', 'OBS_VALUE']]\n",
    "df_ST_IR = df_ST_IR_selected.pivot_table(index='TIME_PERIOD', columns='Reference area', values='OBS_VALUE')\n",
    "df_ST_IR.columns = [f'ST_IR_{col}' for col in df_ST_IR.columns]\n",
    "df_ST_IR.columns = [col.replace(\" \", \"_\") for col in df_ST_IR.columns]\n",
    "df_ST_IR = df_ST_IR.rename(columns={'ST_IR_Slovak_Republic': 'ST_IR_Slovakia'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données d'indice à la consommation des prix <a class=\"anchor\" id=\"partie24\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous récupérons les données relatives à l'indice à la consommation des prix, qui nécessite des modifications car les données actuelles sont mensuelles et non trimestrielles. Nous faisons le choix de les transformer en trimestrielles en attribuant les moyennes mensuelles sur trois mois à notre valeur. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données\n",
    "df_CPI=pd.read_csv('Données_extraites/CPI_annual_eurostat_1996-2024.csv', encoding='utf-8')\n",
    "\n",
    "# Sélection des colonnes nécessaires avec les pays sélectionnés\n",
    "df_CPI_selected = df_CPI[df_CPI['geo'].isin(countries_selected)][['geo', 'TIME_PERIOD', 'OBS_VALUE']]\n",
    "\n",
    "# Modification du format pour avoir les périodes en index et les noms des pays en nom de colonnes\n",
    "df_CPI = df_CPI_selected.pivot_table(index='TIME_PERIOD', columns='geo', values='OBS_VALUE')\n",
    "\n",
    "# Transformation des colonnes en CPI_Nom_du_pays\n",
    "df_CPI.columns = [f'CPI_{col}' for col in df_CPI.columns]\n",
    "df_CPI.columns = [col.replace(\" \", \"_\") for col in df_CPI.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous transformons ici les données mensuelles en trimestrielles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion des mois en trimestre\n",
    "df_CPI.index = pd.PeriodIndex(df_CPI.index, freq='Q')\n",
    "\n",
    "# Pour chaque trimestre on a donc 3 valeurs on fait donc la moyenne\n",
    "df_CPI = df_CPI.groupby(df_CPI.index).mean()\n",
    "\n",
    "# Modification du format de l'index qui est YYYYQQ en YYYY-QQ pour l'accorder aux autres tables\n",
    "df_CPI.index = df_CPI.index.astype(str).str.replace(r'(\\d{4})Q(\\d)', r'\\1-Q\\2', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données de croissance potentielle <a class=\"anchor\" id=\"partie25\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous récupérons les données relatives à l'étude de la croissance potentielle sur un dataframe de la banque mondiale. Il nous faut faire attenion aux noms donnés à la Tchéquie et la Slovaquie qui sont Czech Republic et Slovak Republic et non Czechia et Slovakia comme nous le nommons dans notre nomenclature.\n",
    "\n",
    "De plus les données sont annuelles, donc pour les rendre trimestrielles nous les divisons par 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Excel file format cannot be determined, you must specify an engine manually.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Chargement des données \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df_potential_growth= \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/home/onyxia/work/Stat-App/Données_extraites/GDP_trimestriel_eurostat.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPotentialGrowthMeasures\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Modification des colonnes (pour garder une homogénéité entre les différents df)\u001b[39;00m\n\u001b[32m      5\u001b[39m df_potential_growth= df_potential_growth.rename(columns={\u001b[33m'\u001b[39m\u001b[33mCountry\u001b[39m\u001b[33m'\u001b[39m:\u001b[33m'\u001b[39m\u001b[33mgeo\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mYear\u001b[39m\u001b[33m'\u001b[39m:\u001b[33m'\u001b[39m\u001b[33mTIME_PERIOD\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mHP: Potential real GDP growth (percent)\u001b[39m\u001b[33m'\u001b[39m:\u001b[33m'\u001b[39m\u001b[33mOBS_VALUE\u001b[39m\u001b[33m'\u001b[39m})\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/pandas/io/excel/_base.py:495\u001b[39m, in \u001b[36mread_excel\u001b[39m\u001b[34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[39m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[32m    494\u001b[39m     should_close = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m     io = \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine != io.engine:\n\u001b[32m    502\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    503\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mEngine should not be specified when passing \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    504\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    505\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/pandas/io/excel/_base.py:1554\u001b[39m, in \u001b[36mExcelFile.__init__\u001b[39m\u001b[34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m   1550\u001b[39m     ext = inspect_excel_format(\n\u001b[32m   1551\u001b[39m         content_or_path=path_or_buffer, storage_options=storage_options\n\u001b[32m   1552\u001b[39m     )\n\u001b[32m   1553\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1554\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1555\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mExcel file format cannot be determined, you must specify \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1556\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33man engine manually.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1557\u001b[39m         )\n\u001b[32m   1559\u001b[39m engine = config.get_option(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mio.excel.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.reader\u001b[39m\u001b[33m\"\u001b[39m, silent=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   1560\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m engine == \u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mValueError\u001b[39m: Excel file format cannot be determined, you must specify an engine manually."
     ]
    }
   ],
   "source": [
    "# Chargement des données \n",
    "df_potential_growth= pd.read_excel(\"Données_extraites/GDP_trimestriel_eurostat.csv\",sheet_name=\"PotentialGrowthMeasures\")\n",
    "\n",
    "# Modification des colonnes (pour garder une homogénéité entre les différents df)\n",
    "df_potential_growth= df_potential_growth.rename(columns={'Country':'geo', 'Year':'TIME_PERIOD','HP: Potential real GDP growth (percent)':'OBS_VALUE'})\n",
    "df_potential_growth = df_potential_growth[df_potential_growth['TIME_PERIOD'] >= 1995]\n",
    "\n",
    "# Choix des colonnes nécessaires avec les pays sélectionnés. \n",
    "df_potential_growth_selected = df_potential_growth[df_potential_growth['geo'].isin(countries_selected)][['geo', 'TIME_PERIOD', 'OBS_VALUE']]\n",
    "\n",
    "# Modification du format pour avoir les périodes en index et les noms des pays en nom de colonnes\n",
    "df_potential_growth= df_potential_growth_selected.pivot_table(index='TIME_PERIOD', columns='geo', values='OBS_VALUE')\n",
    "\n",
    "# Transformation des colonnes en P_Growth_pays\n",
    "df_potential_growth = df_potential_growth.rename(columns={'Czech Republic': 'Czechia'})\n",
    "df_potential_growth = df_potential_growth.rename(columns={'Slovak Republic': 'Slovakia'})\n",
    "df_potential_growth.columns = [f'P_Growth_{col}' for col in df_potential_growth.columns]\n",
    "df_potential_growth.columns = [col.replace(\" \", \"_\") for col in df_potential_growth.columns]\n",
    "\n",
    "# Trimestrialisation \n",
    "df_potential_growth.index = pd.to_datetime(df_potential_growth.index, format=\"%Y\")\n",
    "quarters = ['Q1', 'Q2', 'Q3', 'Q4'] * (len(df_potential_growth) // 4 + 1)\n",
    "\n",
    "# Répéter chaque ligne 4 fois pour chaque trimestre\n",
    "df_quarterly = df_potential_growth.loc[df_potential_growth.index.repeat(4)].copy()\n",
    "\n",
    "# Générer les trimestres (Q1, Q2, Q3, Q4) pour chaque année\n",
    "df_quarterly['Quarter'] = quarters[:len(df_quarterly)]\n",
    "\n",
    "# Diviser toutes les colonnes numériques par 4\n",
    "df_quarterly.iloc[:, :] = df_quarterly.iloc[:, :].div(4)\n",
    "\n",
    "# Convertir l'index annuel en format trimestriel\n",
    "df_quarterly.index = [f\"{year.year}-{q}\" for year, q in zip(df_potential_growth.index.repeat(4), df_quarterly['Quarter'])]\n",
    "\n",
    "# Supprimer la colonne \"Quarter\" qui n'est plus nécessaire\n",
    "df_quarterly.drop(columns=['Quarter'], inplace=True)\n",
    "df_potential_growth = df_quarterly.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création de la base de données <a class=\"anchor\" id=\"partie3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que tous les dataframes sont construits pour les variables d'intérêts nous concaténons les dataframes pour en avoir un unique qui servira de base de données pour la suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concaténation des DataFrames\n",
    "df_concat = pd.concat([df_GDP, df_CPI,df_LT_IR, df_ST_IR, df_working_hours, df_potential_growth], axis=1)\n",
    "\n",
    "# Réorganisation des colonnes pour que celles de chaque pays soient côte à côte\n",
    "ordered_columns = []\n",
    "\n",
    "# Modification la liste de base pour qu'elle corresponde au format de notre dataframe\n",
    "countries_selected.remove('Slovak Republic')\n",
    "countries_selected.remove('United Kingdom')\n",
    "countries_selected.remove('Czech Republic')\n",
    "countries_selected.append('United_Kingdom')\n",
    "\n",
    "# Tri\n",
    "for country in countries_selected:\n",
    "    ordered_columns.append(f'CPI_{country}')\n",
    "    ordered_columns.append(f'PIB_{country}')\n",
    "    ordered_columns.append(f'LT_IR_{country}')\n",
    "    ordered_columns.append(f'ST_IR_{country}')\n",
    "    ordered_columns.append(f'WH_{country}')\n",
    "    ordered_columns.append(f'P_Growth_{country}')\n",
    "\n",
    "df_final = df_concat[ordered_columns]\n",
    "\n",
    "# Exportation\n",
    "df_final.to_excel('base_de_données_v1.xlsx', index=True, engine='openpyxl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
