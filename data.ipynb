{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Récupération et formatage des données**\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction<a class=\"anchor\" id=\"partie1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook contient les codes nécessaires à la récupération et au formatage des données. Les données ont été récupéré sur le site de [l'OCDE](https://data-explorer.oecd.org/) et sur celui [d'Eurostat](https://ec.europa.eu/eurostat/fr/data/database). \n",
    "\n",
    "Nous récupérons les données en csv et les transformons en un unique csv contenant pour chacun des pays les valeurs trimestrielles (de Q1 en 1995 à Q3 de 2024 <span style=\"color:red ; font-size:20px;\"> faire attention les working hours ne vont qu'au Q3 de 2024 </span>) de PIB, d'heure de travail, des taux d'intérêts à court et long terme et de l'indice à la consommation des prix. Pour l'instant il nous manque aussi les anticipations des taux et les rendements des marchés financiers. Le csv final de ce notebook servira de base de données par la suite. \n",
    "\n",
    "<span style=\"color:red ; font-size:20px;\"> Compléter avec les variables manquantes et mettre une liste des pays (si on ne la met pas ailleurs) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sommaire\n",
    "\n",
    "* [Introduction](#partie1)\n",
    "* [Récupération des données](#partie2)\n",
    "    * [Données de PIB](#partie21)\n",
    "    * [Données d'heures de travail](#partie22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Récupération des données <a class=\"anchor\" id=\"partie2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données de PIB <a class=\"anchor\" id=\"partie21\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous extrayons les données relatives au PIB depuis Eurostat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charge les données depuis le csv \n",
    "df_GDP = pd.read_csv(\"Données_extraites/GDP_trimestriel_eurostat.csv\", encoding='utf-8')\n",
    "\n",
    "# Sélectionne les colonnes nécessaires\n",
    "df_GDP_selected = df_GDP[['geo', 'TIME_PERIOD', 'OBS_VALUE']]\n",
    "\n",
    "# Change le format avec les périodes en index et les noms des pays en noms de colonnes\n",
    "df_GDP_pivot = df_GDP_selected.pivot_table(index='TIME_PERIOD', columns='geo', values='OBS_VALUE')\n",
    "\n",
    "# Transforme le nom des colonnes en PIB_Nom_du_pays\n",
    "df_GDP_pivot.columns = [f'PIB_{col}' for col in df_GDP_pivot.columns]\n",
    "df_GDP_pivot.columns = [col.replace(\" \", \"_\") for col in df_GDP_pivot.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_GDP_pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données de d'heure de travail <a class=\"anchor\" id=\"partie22\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous extrayons les données relatives aux heures de travail depuis Eurostat. Nous avons trois base de données pour les heures de travail. Une base annuelle de 1995 à 1997, et deux bases trimestrielles allant du Q1 de 1998 au Q4 de 2007 et du Q1 de 2008 au Q3 de 2024.\n",
    "\n",
    "Nous voulons traiter les données dans l'ordre chronologique. Nous devons donc pour la première période récupérer les données annuelles et les transformer en trimestrielles, nous choisissons d'interpoler les données manquantes de manière linéaire en donnant la valeur annuelle au Q1. Pour cela nous avons besoin de traiter les données de 1998 à 2007 avant afin de pouvoir faire l'interpolation entre le Q1 de 1997 et celui de 1998."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charge les données de 1995 à 1997 \n",
    "df_working_hours_95_97 = pd.read_csv(\"Données_extraites/Working_hours_eurostat_1995-1997.csv\", encoding='utf-8')\n",
    "\n",
    "# Sélectionne les colonnes nécessaires\n",
    "df_working_hours_95_97_selected = df_working_hours_95_97[['geo', 'TIME_PERIOD', 'OBS_VALUE']]\n",
    "\n",
    "# Change le format avec les périodes en index et les noms des pays en noms de colonnes\n",
    "df_working_hours_95_97_pivot = df_working_hours_95_97_selected.pivot_table(index='TIME_PERIOD', columns='geo', values='OBS_VALUE')\n",
    "\n",
    "# Transforme le nom des colonnes en WH_Nom_du_pays\n",
    "df_working_hours_95_97_pivot.columns = [f'WH_{col}' for col in df_working_hours_95_97_pivot.columns]\n",
    "df_working_hours_95_97_pivot.columns = [col.replace(\" \", \"_\") for col in df_working_hours_95_97_pivot.columns]\n",
    "\n",
    "# Même processus pour celles de 1998 à 2007\n",
    "df_working_hours_98_07 = pd.read_csv(\"Données_extraites/Working_hours_eurostat_1998-2007.csv\", encoding='utf-8')\n",
    "df_working_hours_98_07_selected = df_working_hours_98_07[['geo', 'TIME_PERIOD', 'OBS_VALUE']]\n",
    "df_working_hours_98_07_pivot = df_working_hours_98_07_selected.pivot_table(index='TIME_PERIOD', columns='geo', values='OBS_VALUE')\n",
    "df_working_hours_98_07_pivot.columns = [f'WH_{col}' for col in df_working_hours_98_07_pivot.columns]\n",
    "df_working_hours_98_07_pivot.columns = [col.replace(\" \", \"_\") for col in df_working_hours_98_07_pivot.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération du Q1 de 1998 et suppresion de la table pour éviter les doublons lors de la concaténation\n",
    "Q1_1998 =  df_working_hours_98_07_pivot.loc[['1998-Q1']]\n",
    "df_working_hours_98_07_pivot = df_working_hours_98_07_pivot.drop(index='1998-Q1', errors='ignore')\n",
    "\n",
    "# On ajoute les trimestres vierges aux données de 1995 à 1998 pour ensuite les compléter par interpolation\n",
    "new_index = []\n",
    "values = []\n",
    "for year in df_working_hours_95_97_pivot.index:\n",
    "    # Ajouter Q1 pour chaque année (avec la valeur annuelle)\n",
    "    new_index.append(f\"{year}-Q1\")\n",
    "    values.append(df_working_hours_95_97_pivot.loc[year].values)\n",
    "    \n",
    "    # Ajouter Q2, Q3 et Q4 (lignes vides pour l'instant)\n",
    "    for quarter in ['Q2', 'Q3', 'Q4']:\n",
    "        new_index.append(f\"{year}-{quarter}\")\n",
    "        values.append([None] * len(df_working_hours_95_97_pivot.columns))\n",
    "\n",
    "# Création du dataframe avec les lignes vides\n",
    "df_working_hours_95_97_pivot = pd.DataFrame(values, index=new_index, columns=df_working_hours_95_97_pivot.columns)\n",
    "df_working_hours_95_97_pivot.index.name = 'TIME_PERIOD'\n",
    "\n",
    "df_working_hours_95_97_pivot = pd.concat([df_working_hours_95_97_pivot, Q1_1998])\n",
    "\n",
    "# Interpolation\n",
    "df_working_hours_95_97_pivot = df_working_hours_95_97_pivot.interpolate(method='linear')\n",
    "print(df_working_hours_95_97_pivot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
